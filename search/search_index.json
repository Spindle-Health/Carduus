{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Carduus","text":"<p>The open source implementation of the Open Privacy Preserving Record Linkage (OPPRL) protocol build on Spark.</p>"},{"location":"#rationale","title":"Rationale","text":"<p>Privacy Preserving Record Linkage (PPRL) is crucial component to data de-identification systems. PPRL obfuscate identifying attributes or other sensitive information about the subjects described in the records of a dataset while still preserving the ability to link records pertaining to the same subject through the use of an encrypted token. This practice is sometimes referred to as \"tokenization\" and is one of the components of data de-identification.</p> <p>The task of PPRL is to replace the attributes of a every record denoting Personally Identifiable Information (PII) with a token produced by a one-way cryptographic function. This prevents observers of the tokenized data from obtaining the PII. The tokens are produced deterministically such that input records with the same, or similar, PII attributes will produce an identical token. This allows practitioners to associate records across datasets that are highly likely to belong to the same data subject without having access to PII.</p> <p>Tokenization is also used when data is shared between organizations to limit, or in some cases fully mitigate, the risk of subject re-identification in the event that an untrusted third party gains access to a dataset containing sensitive data. Each party produced encrypted tokens using a different secret key so that any compromised data asset is, at worst, only matchable to other datasets maintained by the same party. During data sharing transactions, a specific \"transcryption\" data flow is used to first re-encrypt the sender's tokens into ephemeral tokens that do not match tokens in any other dataset and can only be ingested using the recipients secret key. At no point in the \"transcryption\" data flow is the original PII used.</p> <p>Carduus is the first (and canonical) implementation of the Open Privacy Preserving Record Linkage (OPPRL) protocol. This protocol presents a standardized methodology for tokenization that can be implemented in any data system to increase interoperability. The carduus implementation is a python library that distributes the tokenization workload using apache Spark across multiple cores or multiple machines in a high performance computing cluster for efficient tokenization of any scale datasets.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>See the getting started guide on the project's web page for an detailed explanation of how carduus is used including example code snippets.</p> <p>The full API and an example usage on Databricks are also provided on the project's web page.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Please refer to the carduus contributing guide for information on how to get started contributing to the project.</p>"},{"location":"#organizations-that-have-contributed-to-carduus","title":"Organizations that have contributed to Carduus","text":""},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":"<p>These community rules are put in place in order to ensure that development of  carduus stays focused and productive.</p>"},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported anonymously using this form. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p> <p>For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq</p>"},{"location":"CONTRIBUTING/","title":"Contributing to carduus","text":"<p>All interest in carduus, as a user or contributor, is greatly appreciated! This document will go into detail on how to contribute to the development of the carduus software package.</p> <p>If you are looking to contribute to the research and design of the Open Privacy Preserving Record Linkage (OPPRL) specification, see this page.</p>"},{"location":"CONTRIBUTING/#before-contributing","title":"Before Contributing","text":"<p>Before reading further we ask that you read our Code of Conduct which will be enforced by the maintainers in order to ensure that development of carduus stays focused and productive.</p> <p>If you are new to contributing to open source, or GitHub, the following links may be helpful starting places:</p> <ul> <li>How to Contribute to Open Source</li> <li>Understanding the GitHub flow</li> </ul>"},{"location":"CONTRIBUTING/#we-use-github-flow","title":"We Use Github Flow","text":"<p>This means that all code and documentation changes happen through pull requests. We actively welcome your pull requests. We highly recommend the following workflow.</p> <ol> <li>Fork the repo and create your branch from <code>main</code>.</li> <li>If you've added code that should be tested, add tests.</li> <li>If you've changed APIs, update the documentation.</li> <li>Ensure the test suite passes.</li> <li>Create the pull request.</li> </ol>"},{"location":"CONTRIBUTING/#any-contributions-you-make-will-be-under-the-mit-software-license","title":"Any contributions you make will be under the MIT Software License","text":"<p>In short, when you submit code changes, your submissions are understood to be under the same MIT License that covers the project. Feel free to contact the maintainers if that's a concern.</p>"},{"location":"CONTRIBUTING/#how-to-contribute-a","title":"How to contribute a ...","text":""},{"location":"CONTRIBUTING/#bug-report","title":"Bug Report","text":"<p>We use GitHub issues to track public bugs. Report a bug by opening a new issue.</p> <p>Great Bug Reports tend to have at least the following:</p> <ul> <li>A quick summary and/or background</li> <li>The steps to reproduce.</li> <li>When possible, minimal code that reproduces the bug.</li> <li>A description of what you expected versus what actually happens.</li> </ul>"},{"location":"CONTRIBUTING/#feature-request","title":"Feature Request","text":"<p>We like to hear in all feature requests and discussion around the direction of the project. The best place to discuss future features is the project's discussion page under the ideas category.</p>"},{"location":"CONTRIBUTING/#bug-fix-new-feature-documentation-improvement-or-other-change","title":"Bug fix, new feature, documentation improvement, or other change.","text":"<p>We welcome contribution to the codebase via pull requests. In most cases, it is beneficial to discuss your change with the community via a GitHub issue or discussion before working on a pull request. Once you decide to work on a pull request, please follow the workflow outlined in the above sections.</p> <p>Once you open the pull request, it will be tested with by CI and reviewed by other contributors (including at least one project maintainer). After all iterations of review are finished, one of the project maintainers will merge your pull request.</p>"},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<p>When working on a code change or addition to carduus, it is expected that all changes  pass existing tests and probably introduce new tests to ensure stability of future changes. </p> <p>Before you are able to run tests, you must have a virtual environment for the project. Carduus uses  Poetry to manage Python environments. Once poetry is installed, run the following in  the root directory of the project.</p> <pre><code>poetry install\n</code></pre> <p>To run the test suite, use the following command in the root of the project.</p> <pre><code>poetry run pytest\n</code></pre>"},{"location":"LICENSE/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2024 Spindle Health LLC</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/","title":"Functions","text":"<p>THe core functionality of carduus is provided by a the following functions that operate over pyspark <code>DataFrame</code>.</p> <p>The <code>TokenSpec</code> class allows for custom tokens, beyond the builtin OPPRL tokens, to be generated during tokenization. See the custom tokens guide for more information.</p>"},{"location":"api/#carduus.token.tokenize","title":"carduus.token.tokenize","text":"<pre><code>tokenize(df, pii_transforms, tokens, key_provider=None)\n</code></pre> <p>Replaces all PII attributes with encrypted tokens.</p> <p>All PII columns found in the <code>DataFrame</code> are normalized using the provided <code>pii_transforms</code>. All PII attributes provided by the enhancements of the <code>pii_transforms</code> are added if they are not already present in the <code>DataFrame</code>. The fields of each <code>TokenSpec</code> from <code>tokens</code> are hashed and encrypted together according to the OPPRL specification. Finally, the PII columns are dropped.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The pyspark <code>DataFrame</code> containing all PII attributes.</p> required <code>pii_transforms</code> <code>dict[str, PiiTransform | OpprlPii]</code> <p>A dictionary that maps column names of <code>df</code> to PiiTransform objects to specify how each raw PII column is normalized and enhanced into derived PII attributes. Values can also be a member of the OpprlPii enum if using the standard OPPRL tokens.</p> required <code>tokens</code> <code>Iterable[TokenSpec | OpprlToken]</code> <p>A collection of <code>TokenSpec</code> objects that denotes which PII attributes are encrypted into each token. Elements can also be a member of the OpprlToken enum if using the standard OPPRL tokens.</p> required <code>key_provider</code> <code>EncryptionKeyProvider | None</code> <p>An optional <code>EncryptionKeyProvider</code> instance that serves your private keys and the public keys of the parties you exchange data with. Default is an instance of <code>SparkConfKeyProvider</code> which looks for encryption keys loaded as spark configuration properties.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The <code>DataFrame</code> with PII columns replaced by encrypted tokens.</p>"},{"location":"api/#carduus.token.transcrypt_out","title":"carduus.token.transcrypt_out","text":"<pre><code>transcrypt_out(\n    df, token_columns, recipient, key_provider=None\n)\n</code></pre> <p>Prepares a <code>DataFrame</code> containing encrypted tokens to be sent to a specific trusted party by re-encrypting the tokens using the recipient's public key without exposing the original PII.</p> <p>Output tokens will be unmatchable to any dataset or within the given dataset until the intended recipient processes the data with <code>transcrypt_in</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Spark <code>DataFrame</code> with token columns to transcrypt.</p> required <code>token_columns</code> <code>Iterable[str]</code> <p>The collection of column names that correspond to tokens.</p> required <code>recipient</code> <code>str</code> <p>The name of the recipient that will be receiving transcrypted data. Used to lookup the appropriate public keys for asymmetric encryption.</p> required <code>key_provider</code> <code>EncryptionKeyProvider | None</code> <p>An optional <code>EncryptionKeyProvider</code> instance that serves your private keys and the public keys of the parties you exchange data with. Default is an instance of <code>SparkConfKeyProvider</code> which looks for encryption keys loaded as spark configuration properties.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The <code>DataFrame</code> with the original encrypted tokens re-encrypted for sending to the recipient.</p>"},{"location":"api/#carduus.token.transcrypt_in","title":"carduus.token.transcrypt_in","text":"<pre><code>transcrypt_in(df, token_columns, key_provider=None)\n</code></pre> <p>Used by the recipient of a <code>DataFrame</code> containing tokens in the intermediate representation produced by <code>transcrypt_out</code> to re-encrypt the tokens such that they will match with other datasets</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Spark <code>DataFrame</code> with token columns to transcrypt.</p> required <code>token_columns</code> <code>Iterable[str]</code> <p>The collection of column names that correspond to tokens.</p> required <code>key_provider</code> <code>EncryptionKeyProvider | None</code> <p>An optional <code>EncryptionKeyProvider</code> instance that serves your private keys and the public keys of the parties you exchange data with. Default is an instance of <code>SparkConfKeyProvider</code> which looks for encryption keys loaded as spark configuration properties.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The <code>DataFrame</code> with the original encrypted tokens re-encrypted for sending to the destination.</p>"},{"location":"api/#carduus.token.TokenSpec","title":"<code>carduus.token.TokenSpec</code>  <code>dataclass</code>","text":"<p>An collection of PII fields that will be encrypted together to create a token.</p> <p>For an enum of standard <code>TokenSpec</code> instances that comply with the Open Privacy Preserving Record Linkage protocol see <code>OpprlToken</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the column that holds these tokens.</p> <code>fields</code> <code>Iterable[str]</code> <p>The PII fields to encrypt together to create token values.</p>"},{"location":"api/#opprl-implementation","title":"OPPRL Implementation","text":"<p>Although carduus is designed to be extensible, most users will want to use the tokenization procedure proposed by the Open Privacy Preserving Record Linkage (OPPRL) protocol. This open specification proposes standard ways of normalizing, enhancing, and encrypting data such that all user across all OPPRL implementations, including carduus, can share data between trusted parties.</p> <p>The following two <code>enum</code> objects provide <code>PiiTransform</code> instances and <code>TokenSpec</code> instances that comply with OPPRL. These can be passed to the column mapping and token set arguments of <code>tokenize</code> respectively.</p>"},{"location":"api/#carduus.token.OpprlPii","title":"<code>carduus.token.OpprlPii</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Enum of PiiTransform objects for the PII fields supported by the Open Privacy Preserving Record Linkage specification.</p> <p>Attributes:</p> Name Type Description <code>first_name</code> <code>NameTransform</code> <p>PiiTransform implementation for a subject's first name according to the OPPRL standard.</p> <code>middle_name</code> <code>NameTransform</code> <p>PiiTransform implementation for a subject's middle name according to the OPPRL standard.</p> <code>last_name</code> <code>NameTransform</code> <p>PiiTransform implementation for a subject's last (aka family) name according to the OPPRL standard.</p> <code>gender</code> <code>GenderTransform</code> <p>PiiTransform implementation for a subject's gender according to the OPPRL standard.</p> <code>birth_date</code> <code>DateTransform</code> <p>PiiTransform implementation for a subject's date of birth according to the OPPRL standard.</p>"},{"location":"api/#carduus.token.OpprlToken","title":"<code>carduus.token.OpprlToken</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Enum of <code>TokenSpec</code> objects that meet the Open Privacy Preserving Record Linkage tokenization specification.</p> <p>Attributes:</p> Name Type Description <code>opprl_token_1</code> <p>Standard OPPRL token #1. Creates tokens based on <code>first_initial</code>, <code>last_name</code>, <code>gender</code>, and <code>birth_date</code>.</p> <code>opprl_token_2</code> <p>Standard OPPRL token #2. Creates tokens based on <code>first_soundex</code>, <code>last_soundex</code>, <code>gender</code>, and <code>birth_date</code>.</p>"},{"location":"api/#encryption-key-management","title":"Encryption Key Management","text":"<p>See the encryption key section of the \"Getting started\" guide for details about how Carduus accesses encryption keys.</p>"},{"location":"api/#carduus.keys.SparkConfKeyProvider","title":"<code>carduus.keys.SparkConfKeyProvider</code>","text":"<p>             Bases: <code>EncryptionKeyProvider</code></p>"},{"location":"api/#carduus.keys.SimpleKeyProvider","title":"<code>carduus.keys.SimpleKeyProvider</code>","text":"<p>             Bases: <code>EncryptionKeyProvider</code></p>"},{"location":"api/#carduus.keys.generate_pem_keys","title":"carduus.keys.generate_pem_keys","text":"<pre><code>generate_pem_keys(key_size=2048)\n</code></pre> <p>Generates a fresh RSA key pair.</p> <p>Parameters:</p> Name Type Description Default <code>key_size</code> <code>int</code> <p>The size (in bits) of the key.</p> <code>2048</code> <p>Returns:</p> Type Description <code>tuple[bytes, bytes]</code> <p>A tuple containing the private key and public key bytes. Both in the PEM encoding.</p>"},{"location":"api/#interfaces","title":"Interfaces","text":"<p>Carduus offers interfaces that can be extended by the user to add additional behaviors to the tokenization and transcryption processes.</p> <p>The <code>PiiTransform</code> abstract base class can be extended to add support for custom PII attributes, normalizations, and enhancements. See the custom PII guide for more details.</p> <p>The <code>EncryptionKeyProvider</code> abstract base class can be extended to delegate the retrieval of encryption keys to the preferred secret management service for your organization.</p>"},{"location":"api/#carduus.token.PiiTransform","title":"<code>carduus.token.PiiTransform</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for normalization and enhancement of a specific PII attribute.</p> <p>Intended to be extended by users to add support for building tokens from a custom PII attribute.</p>"},{"location":"api/#carduus.token.PiiTransform.normalize","title":"<code>normalize(column, dtype)</code>","text":"<p>A normalized representation of the PII column.</p> <p>A normalized value has eliminated all representation or encoding differences so all instances of the same logical values have identical physical values. For example, text attributes will often be normalized by filtering to alpha-numeric characters and whitespace, standardizing to whitespace to the space character, and converting all alpha characters to uppercase to ensure that all ways of representing the same phrase normalize to the exact same string.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>Column</code> <p>The spark <code>Column</code> expression for the PII attribute being normalized.</p> required <code>dtype</code> <code>DataType</code> <p>The spark <code>DataType</code> object of the <code>column</code> object found on the <code>DataFrame</code> being normalized. Can be used to delegate to different normalization logic based on different schemas of input data. For example, a subject's birth date may be a <code>DateType</code>, <code>StringType</code>, or <code>LongType</code> on input data and thus requires corresponding normalization into a <code>DateType</code>.</p> required <p>Returns:</p> Type Description <code>Column</code> <p>The normalized version of the PII attribute.</p>"},{"location":"api/#carduus.token.PiiTransform.enhancements","title":"<code>enhancements(column)</code>","text":"<p>A collection of PII attributes that can be automatically derived from a given normalized PII attribute</p> <p>If an implementation of PiiTransform does not override this method, it is assumed that no enhancements can be derived</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>Column</code> <p>The normalized PII column to produce enhancements from.</p> required Return <p>A <code>dict</code> with keys that correspond to the PII attributes of the ___ and values that correspond to the <code>Column</code> expression that produced the new PII from a normalized input attribute.</p>"},{"location":"api/#carduus.keys.EncryptionKeyProvider","title":"<code>carduus.keys.EncryptionKeyProvider</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract base class for serving encryption keys to carduus. Can be implemented to call out to whichever service you use to manage encryption keys.</p>"},{"location":"api/#carduus.keys.EncryptionKeyProvider.private_key","title":"<code>private_key()</code>  <code>abstractmethod</code>","text":"<p>Provides your private key.</p>"},{"location":"api/#carduus.keys.EncryptionKeyProvider.public_key_of","title":"<code>public_key_of(recipient)</code>  <code>abstractmethod</code>","text":"<p>Provides the public key of a specific recipient that you share data with.</p>"},{"location":"opprl/","title":"Open Privacy Preserving Record Linkage","text":"<p>Open Privacy Preserving Record Linkage (OPPRL) is a protocol for a privacy preserving record linkage system that can be implemented across data systems to assist in the de-identification of data in a way that preserves privacy while enabling sharing of data assets between trusted organizations.</p> <p>Implementers can find the full specification on the OPPRL Specification page.</p> <p>As an open specification, all practitioners that interact with OPPRL implementations are invited to contribute to discussion, research, and proposals for improvements to the specification. For details on how to participate, see the OPPRL contributing guide.</p>"},{"location":"guides/custom-key-provider/","title":"Implementing Custom Key Providers","text":"<p>One of Carduus's primary design goals is to be usable in any context with a compatible Python environment. A wide variety of users and organizations may want to use Carduus and this implies many different preferred ways of managing secrets, including encryption keys. The direct users of Carduus may not be authorized to see all encryption keys and there may be layers of authentication and access control that are required before Carduus can be deployed within an organization.</p> <p>Over time, Carduus hopes to provide built-in integrations to commonly used secret management services. For example, Carduus's default method of retrieving keys from Spark session properties is well aligned with the model of how Databricks manages secrets.</p> <p>In scenarios where Carduus does not supply a method of accessing secrets that meets your organization's requirements, you can extend the <code>EncryptionKeyProvider</code> abstract base class with your own implementation and provide an instance of your implementation to all of the relevant Carduus functions.</p>"},{"location":"guides/custom-key-provider/#the-encryptionkeyprovider-interface","title":"The <code>EncryptionKeyProvider</code> Interface","text":"<p>The <code>EncryptionKeyProvider</code> base class has two abstract methods that must be defined in it's concrete implementations. The following code snippet shows the signatures of these methods.</p> <pre><code>class EncryptionKeyProvider(ABC):\n\n    @abstractmethod\n    def private_key(self) -&gt; bytes:\n        \"\"\"Provides your private key.\"\"\"\n        ...\n\n    @abstractmethod\n    def public_key_of(self, recipient: str) -&gt; bytes:\n        \"\"\"Provides the public key of a specific recipient that you share data with.\"\"\"\n        ...\n</code></pre> <p>The <code>private_key</code> method returns a instance of <code>bytes</code> that contains your organization's private RSA key in the PKCS #8 format using the PEM encoding. This Should begin with <code>b\"-----BEGIN PRIVATE KEY-----\\n\"</code> and end with <code>b\"\\n-----END PRIVATE KEY-----\\n\"</code> with base64 encoded bytes in between.</p> <p>The <code>public_key_of</code> method should perform some kind of lookup to return the public RSA key of the given recipient. If found, the public key should be represented as an instance of <code>bytes</code> in the SubjectPublicKeyInfo format using the PEM encoding. This Should begin with <code>b\"-----BEGIN PUBLIC KEY-----\\n\"</code> and end with <code>b\"\\n-----END PUBLIC KEY-----\\n\"</code> with base64 encoded bytes in between. If the lookup fails to find a public key for the given recipient, it is recommended that a Python <code>KeyError</code> is raised.</p>"},{"location":"guides/custom-key-provider/#contributing-key-providers","title":"Contributing Key Providers","text":"<p>If you implement an <code>EncryptionKeyProvider</code> for a general purposes and publicly available secret management system, a contribution Carduus is encouraged. See the contributing guide for more information.</p>"},{"location":"guides/custom-pii/","title":"Using Custom PII","text":"<p>Carduus applies normalizations to incoming PII to account for representation differences that often don't indicate a different true identity for the subject. After normalizing the PII columns present on the data provided by the user, Carduus derives additional implicit PII attributes and adds them to the Dataset if they aren't already present. The procedure is called \"enhancement\". For example, a <code>first_initial</code> attributes can be derived from a <code>first_name</code> attribute by taking the first letter.</p> <p>Commonly used PII attributes have standard normalization and enhancement rules proposed in the OPPRL protocol. Carduus provides builtin implementations of the normalizations and enhancements via a set of concrete classes that implement the <code>PiiTransform</code> interface.</p> <p>Users may extend the <code>PiiTransform</code> abstract base class and provide instances to the column mapping used by the <code>tokenize</code> function.</p> <p> This guide is incomplete.</p>"},{"location":"guides/custom-tokens/","title":"Defining Custom Token Specifications","text":"<p>In essence, a token is simply the concatenation of multiple PII fields into a single string of text which is passed through a hash and a subsequent cryptographic function. Carduus provides specifications of the tokens proposed in the OPPRL protocol. These tokens are known to have low false positive and false negative match rates for subjects whose PII is close to the distribution found in the United States population, while only relying on a minimal set of PII attributes that are commonly populated in real-world datasets.</p> <p>Some users may want to create tokens by concatenating different PII fields than what is proposed by OPPRL. This is often the case when the datasets of a particular user and the parties they share data with have additional PII beyond what OPPRL leverages that will lead to lower match errors for the sample of subjects used their use case. For a guide on how to extend Carduus with support for additional PII attributes, see this guide</p> <p>To declare a custom token specification, simply instantiate the <code>TokenSpec</code> class provided by Carduus and provide it with a token name and a collection of columns to jointly encrypt.</p> <pre><code>from carduus.token import TokenSpec\n\nmy_token = TokenSpec(name=\"geo_token\", fields=[\"last_name\", \"birth_date\", \"zipcode\"])\n</code></pre> <p>This <code>my_token</code> object can be passed to the <code>tokenize</code> function to replace the PII columns with a <code>geo_token</code> column. If the PII data does not have one or more of the fields referenced by the token definition (after normalization and enhancement) the <code>tokenize</code> function will throw an exception prior to performing any significant workloads.</p>"},{"location":"guides/databricks/","title":"Carduus on Databricks","text":"In\u00a0[\u00a0]: Copied! <pre>pii = spark.createDataFrame(\n    [\n        (1, \"Jonas\", \"Salk\", \"male\", \"1914-10-28\"),\n        (1, \"jonas\", \"salk\", \"M\", \"1914-10-28\"),\n        (2, \"Elizabeth\", \"Blackwell\", \"F\", \"1821-02-03\"),\n        (3, \"Edward\", \"Jenner\", \"m\", \"1749-05-17\"),\n        (4, \"Alexander\", \"Fleming\", \"M\", \"1881-08-06\"),\n    ],\n    (\"label\", \"first_name\", \"last_name\", \"gender\", \"birth_date\")\n)\ndisplay(pii)\n</pre> pii = spark.createDataFrame(     [         (1, \"Jonas\", \"Salk\", \"male\", \"1914-10-28\"),         (1, \"jonas\", \"salk\", \"M\", \"1914-10-28\"),         (2, \"Elizabeth\", \"Blackwell\", \"F\", \"1821-02-03\"),         (3, \"Edward\", \"Jenner\", \"m\", \"1749-05-17\"),         (4, \"Alexander\", \"Fleming\", \"M\", \"1881-08-06\"),     ],     (\"label\", \"first_name\", \"last_name\", \"gender\", \"birth_date\") ) display(pii) labelfirst_namelast_namegenderbirth_date1JonasSalkmale1914-10-281jonassalkM1914-10-282ElizabethBlackwellF1821-02-033EdwardJennerm1749-05-174AlexanderFlemingM1881-08-06 In\u00a0[\u00a0]: Copied! <pre>%pip install carduus\n</pre> %pip install carduus In\u00a0[\u00a0]: Copied! <pre>from carduus.token import tokenize, OpprlPii, OpprlToken\ntokens = tokenize(\n    pii,\n    pii_transforms=dict(\n        first_name=OpprlPii.first_name,\n        last_name=OpprlPii.last_name,\n        gender=OpprlPii.gender,\n        birth_date=OpprlPii.birth_date,\n    ),\n    tokens=[OpprlToken.token1, OpprlToken.token2]\n)\ndisplay(tokens)\n</pre> from carduus.token import tokenize, OpprlPii, OpprlToken tokens = tokenize(     pii,     pii_transforms=dict(         first_name=OpprlPii.first_name,         last_name=OpprlPii.last_name,         gender=OpprlPii.gender,         birth_date=OpprlPii.birth_date,     ),     tokens=[OpprlToken.token1, OpprlToken.token2] ) display(tokens) labelopprl_token_1opprl_token_21d2tUj3yRFPIBSwR/ntUi8v1B/A9H+Q0iNwlz0+OVpO54MER9bRnTgHxOO8Q4IM+gdoxKGJGV9STb6DH2hxKIb50v6IFa+StqSnKRy7GJG4U=DQhKG+AMgrFh16dLiogYy/U9YDLsATVvhMtQ4cHkWmyr8+JmuABYYQV3OJCNLYupaevu9qapeWo80zq+VVumrKwuUXqUCjQzs7ui5qceUVc=1d2tUj3yRFPIBSwR/ntUi8v1B/A9H+Q0iNwlz0+OVpO54MER9bRnTgHxOO8Q4IM+gdoxKGJGV9STb6DH2hxKIb50v6IFa+StqSnKRy7GJG4U=DQhKG+AMgrFh16dLiogYy/U9YDLsATVvhMtQ4cHkWmyr8+JmuABYYQV3OJCNLYupaevu9qapeWo80zq+VVumrKwuUXqUCjQzs7ui5qceUVc=22wnRWhN9Y4DBMeuvwbriLCmz5xVyCNJO1liVdO/bu/nwtTkudQCfmHazpSYftTGVDVfIz8z0gy5eAAap9qKY7D6LmCM4Df6wRttrlh5XBQw=A7fUKAZi/Ra2T6p8y4nsW0DRuI0P4KGatyuj7XyI4LIU+6lRCYukLDxPepOB52xPLDU2J2B9n8YGO9x0dmK+t4ZEAjJNsBnZrKy3hPvN5PY=3I17X+CT3kjqB9l0rAOyiGVYKTzFrSLp4KSHfdUR89rYTyC/d24QcuYZ2VHWVzPawTFNqaIr7oMjgoMCX8gruUSgU42YLoq64KHdRiqTBuQ8=qGCUVyI7MJLkQ9SSrz0uNIFQXDJBcCNdMVneZ/fLdAfn39ZNZgD+6Vm4l20pM/0zKeLRYAHCpJh/AH7UB21ssqzfbSdOkjrGDL51lYZ9fK8=46Ee3NabHaa/lyKsrpou/DqufDgEOVyq3Hb9RKg7GpkoAY3ZlPn9k1iMj6NhJuo4t35i5aixmOr8hXYnBvql0DVQqJwujrk1rdOnNYwhulvs=dbwNqy0rN6hFoHJYnWo9G9REKGLLbJKvvnWYS9uR1gj3x8z6oQENN6K0DqU9INgldMikxac7EG5ZR9wicpVSMDBAy2HbqFcBL4ZHoNWWDoM= In\u00a0[\u00a0]: Copied! <pre>from carduus.token import transcrypt_out\ntokens_to_send = transcrypt_out(\n    tokens, \n    token_columns=(\"opprl_token_1\", \"opprl_token_2\"), \n    destination=\"AcmeCorp\",\n)\ndisplay(tokens_to_send)\n</pre> from carduus.token import transcrypt_out tokens_to_send = transcrypt_out(     tokens,      token_columns=(\"opprl_token_1\", \"opprl_token_2\"),      destination=\"AcmeCorp\", ) display(tokens_to_send) labelopprl_token_1opprl_token_21d8JaP02dS0M+COGihZCp+Kr2piXyNU5yvPhFR1/ajN7m+gr63NsQee8v7WMKnEJkY6/BDOjREQ8sf1iD0xWDsvCM8rCqlG8uFlVKQ4FY2atSGuqHUzHcjGf8eNEsbpM2AZnLliFDssvljVgBy9CpYUti20c8L/TgrVMKd1rSgJaDXjXRHS5abWD6EaD77IV3KpELoii7XhE4xqLV3PIH+5TaF6Yaa7FbLaYtG0+wIQ+huC9H4QLHgGam8JE71k/aznve90koz8/hO0vM5/RpLd+dTQ4MMRCPxt/SBVtJp3fuvPtbVdR+rf5KPuCkS3IvUtOGgUlYKVMovNYA2uUDNg==hyh5cNCkhptFNbbndY/l43GBuTBcDbAdNQWQdznelQVsugwQ9Fip7rC1N0Adj2oBxe+0qL86Mv079BKoDRpHCRIw6aqvHbTJHBV+CuDRmmLUcbFUVTKI3AwGEom2i076wulOX0Wjvs8fXe4vCTX5AZXWwpPCMJUBaMu8zLqgIPtiJhD0UMUsoBwTeFEzxR6sIVBU7E3pFHToYCkT7ISZ55rY+CcsIAI8I5TS0qtYAgDuCWWhp8ZJ2NNRWcWd9qHPMqXWkQ//k75vS0ng018Z4hH0/EVGVVf9iOKGb6ibgTrfmxM0lWDpZqBfjZZ/uExeZsI3EVcQUmzFccWpyB1nYw==1Pj3ZIaIj9/i5N8ZnBpe23u6WfeEXR3nka8J+Y+5pawvmgnAnRFzhTekmcx350Viyp4FHsKh4ogO2J6714oSLm4zaELZhcaPAI0slee/7LnaYZNAArXtg4bxqNdz/vifIvcWj8S+TyrEXsxmzIpgS5nKYG9SRbQ0IO5/Ungxx+GouhGeGC54nlL7dt1dHlgUmMkQx+UH89t+D/C55F/lDmRkhddjiSO1LFIZYyo3xT0F/j5o7b7cI0OoZpvN6OYdrE9IfsfqYFh/RoHhMjfpajYDSUcy6Cq4evcjhEy5XvGqNJpQTToC/A1rmTB5WtFO1oCyVF0HGb+FgHwO9ccVIjw==N3M6t4ZW5/DnzfhYIcUJdCHAorl7lWvrBnZGtInrno3z62V6n1odgQmY6fgXHy5sTTHdujeIn/dRi6PD9rBANjTpi42puSGHf7VLIx9uqr+kSiXGTCBnAHy8C3DNfpxtx4I391/8aM2mbnS/5icuyIKgzZP+fWsFxehfMSLDgW3YMQsgZy0JBSpetk+8Jl1L06pQYHt967zcAvi0JRiUmZHshOGAdkVO1hQGgUDOsHuBrElqkooFfuIw0QC4v1aeqQDtVH3Un/9cJMonmsRtnuRYUZE7aW1Zl/RGYKq1LhegIzL/+JlYuqOHZoSPyB/0O6t7u/USRkkZCUKM+V7ryg==2bLkqSZYRsRZ8/7EQsxE/DU2Rf5n2qxjNiJgNUuJHfTcMLVC3C0tPlS+AztVVwWBj2G+GaA8QoeM7jqfxzou/xK13ggOOIiXWAapqOMT96Z5C3y+GG8och8g9w52Mr/3zKINIe5VLaxoMetH67J5d85gxFtixKTJiQq6GPUiJdm4ice/XACuG1bYtUKB3hfoRE3ZUsgOxQDlocSOcvrLvYK2SRgoRTqP3Upk+Cuemc0n8a0fLEcm3nXBrte2LKL2othx0Zost+ev8SL1LG22LJwjAKhRXDf6s7/DooEsoWaQM4mGImpZAp7CNxuLzL5BAdE2njkq8VTeLM6zkFSxw8Q==N9soErrrifQW4t0ZzwlErWKlbXaSggSve+MT+L0PzZpS+2m/qg+sKSJHDTlM4WWyly/dy0fHgLjANWl4vLAgWl6BwZY51pDVPldBfOD2NfjRmWKhk5vvh0j2BPOEkRn7k0UisUoCqSWglMZMxo6gA5vhUS1s9Gg2e8hg410eCengabReUSEpZpcbyB4yPdPXniwScXLBQX6AjIHEK2lRxtjLI5qWaSwOKeOP+b12Hrxgu3HB9eZ2Yr2Rt1O9+R8z/A5Xvz4NQ2oTxxLAwJ2LBbWbY6CvS/8n5460oSBe28xAG2rl2I96RbzRzoTXni7GNDEjkh27298t5v/HaOD/WA==3lyaQetBbfzUuDoK+u6MLs18H6pH4iafWZNrwc8CKjmilA0mTuUHt9+joXXexkGhkKV37WGnpz4+0lzNOAVQ0c6/LMqRi2FImWh4a1xlk7BM4MDKUY9SNfa562yvxvm3Sast3NHfrYbs/9Nwrd5eXsHwI60DmfRkxbc+P3mUMoK7trvnOG9vHPedKqDh3uXGVf0oAK+d6WLOxN5r5PCldEaqFt/ErDsHUgcvy3F0b6W9+Xx/a9s2x2/ZvcLkfY5oF7+td7a8ghQ9xWzeC8hNt35FcbDe0v1vPkV32UiiO3atKIz1rr2Gag29xaAEonXucwtaIaCGGywFzbMV/CvLC/w==iFz4K/xh2sKLl8dobmZeB1xwtgXySSGmtn8qMPtPk3bJ5rxFKwgM/HxI77td3FFVsPS5sAN1WSDOuVBMwSWkgzX5qGB2qt6FgOdFj4Eh3ihSb9YqKOzTDGD4AzUwTbhYpdF406kji1ERurefGompR+qxgtPWDx9hqBbqwtC+qyp35Wiqp0tMgCn1ZPUC8Bgqb6SC9BakYS/XF8MAnA4mI7ARFvw74VRXdmHmaPox/lFSkUai5mfO2cOZaU6cqlFsLy6AzYTGhJsSQDIooFmyXjnmKq+sNxsliR/p4sCZUCF5nIXQo8uHWFcl+PI0eDidQOop/MVrB/P38E+3dttu4g==4CQdw+tk0Z2/bUzRVsTHv4i0DRPNE7ji/WqaiX3BDNlYKGRim96C6IxuBwElbz0gnvzrc19pc68SBUHF6+aNobR2uLEpQpJiOPGtrfFTvr101kQL/WqKsczgNkU9UVNEcNOiB9yBBNbH+3oevbbQ5uOkblUgf6gNbcN1n3mfRr6b0npaET/EiBwjJMAfHCGZ8KBacqfUn9M8Hv4Ie/tCs5B80fDcmm+GLVKZMCVeUa4olTtl8gOSqGlNNhUbX0K0xlFNzrxQ2G6NiQOy8M0Z4my+adW9o37EbcT03ypzHIKbYvyuiEE73lkAZKR0Rf1uhh51Y0pvTi2ELMXgjDcBn9A==It9sQjB4X15z/1xgmZLg1UrZfmeM7mT++Me5AYQM9weuH8WXs9lQ+AdBeuH2yRly3ETlCz08vEqm/eHl0/z24eLQeHJz0t/S/8Qz2CnO/KX9AKlLr/rj5XVXCFWKkoh/qDPAd28d0OfL5WcbIkVB7uF9UbjZp2SdWEDaPRzFMiBE9OJ2lu/5bZSMjAqRylwwLKDc5jSJNtHzquMvoG+X7b08fzzPe2Nc7ViP9UvqADFGu8vZFhkQ9UiBdglHS05VV0PIcUmpn40pr+evnphX6fOlWgMh/F3T85EVtAtU1AWnH3vqnyqhhMIArHM5W2dflKp657d9x/DytVfa4iiy+Q== In\u00a0[\u00a0]: Copied! <pre>from carduus.keys import SimpleKeyProvider\n\nkeys = SimpleKeyProvider(\n  private_key=dbutils.secrets.getBytes(\"carduus\", \"PrivateKey\"),\n  public_keys={},\n)\n</pre> from carduus.keys import SimpleKeyProvider  keys = SimpleKeyProvider(   private_key=dbutils.secrets.getBytes(\"carduus\", \"PrivateKey\"),   public_keys={}, ) In\u00a0[\u00a0]: Copied! <pre>from carduus.token import transcrypt_in\n\ntokens2 = transcrypt_in(\n    tokens_to_send, \n    token_columns=(\"opprl_token_1\", \"opprl_token_2\"),\n    key_service=keys,\n)\ndisplay(tokens2)\n</pre> from carduus.token import transcrypt_in  tokens2 = transcrypt_in(     tokens_to_send,      token_columns=(\"opprl_token_1\", \"opprl_token_2\"),     key_service=keys, ) display(tokens2) labelopprl_token_1opprl_token_21O47siK/9rItAv6lwaKgbH9MVuvZe0IwaBzEkQBRgHx9MWi02k8Gn/VvxoTsbA+4NB5DFMcAZeCS44azIKPV6M3tNySHQwSSDCQCPo+vGYPc=uoPojmvjl3Mk734UlQb/bDHms7vHiptbYKbWCV1VWiE1svY/nAfp+Lm14b6Y/xJViuvqOrNIzpfItlOgU0UN//VCxg54FDLaZIZGfRhW1co=1O47siK/9rItAv6lwaKgbH9MVuvZe0IwaBzEkQBRgHx9MWi02k8Gn/VvxoTsbA+4NB5DFMcAZeCS44azIKPV6M3tNySHQwSSDCQCPo+vGYPc=uoPojmvjl3Mk734UlQb/bDHms7vHiptbYKbWCV1VWiE1svY/nAfp+Lm14b6Y/xJViuvqOrNIzpfItlOgU0UN//VCxg54FDLaZIZGfRhW1co=2LfRQxBPEW0tEskwxtnooILPEi6/AtbfKCsWsPKMAS455xUeGfzxXdoTIdVnvKrpmT81aQA85dk7QqF+2K7Vjcg291ov2Skz+eMjF7n8DdZM=P9PLhpSz+kWSSVmYQ8yCwAbQpohy/Ua8R1sSPytPpYb+CLN1KigfKedlIHZUWhf1tTq5gOjPeZp80rHtjJpsPbXAG0rWe9pjhP/Vjhdp140=3QWvpT0wMEezlurVFMa+yJIKJdAJQXuie8/VuqqKsSQDaGMDkV1s0PX9RTumY75oQdAwPGTFZvCoOGWn0jIIrdY93T7s0qK3O0raXgZCKtHg=W9BxmxZf1/yqIDx3WCwqq0aPLznw7GATRx7ETrxLYfNBiuozxUBTs5Z3Ig9sErG7owJm16suzKHJ4ICYRtteoni8Ystu2ou7ODgnny/BxOs=4aS/BfI5qw8UnhOWUXyUNQMAaZRKGCC3/l/htFpHYhVecUv1EtRE0ht893KPkZbVpNsw7nORH9TlRbl8vU1WaNz2Kf04sw2iqcMVHx+VjD3s=nWfWyxQcrSfeiMEHr98Z+mq7u3DMT1xdSJ0nrw8nTeKR0s/Gh78f+pDJNooeJUv4vfuuJFFqWEI2dkC5Q99ZBkdwiYnp/cj5Htif/Gk9lHY="},{"location":"guides/databricks/#carduus-databricks-demo","title":"Carduus Databricks Demo\u00b6","text":"<p>This notebook demonstrates the use of the <code>carduus</code> python package from within the Databricks environment to parallelize the tokenization processes using Spark clusters.</p> <p>We use a small 5 row sample dataset of PII, however <code>carduus</code> is capable to distributing the workload of tokenizing and transcrypting large datasets across the cluster.</p>"},{"location":"guides/databricks/#one-time-workspace-setup","title":"One-time Workspace Setup\u00b6","text":"<p>See the Databricks documentation for managing secrets to get started. You will need an to install the Databricks CLI and authenticate as a user that can manage Databricks secrets.</p> <p>Create a secret scope for <code>carduus</code> encryption keys by running the following command with the Databricks CLI.</p> <pre><code>databricks secrets create-scope carduus\n</code></pre> <p>Add your private key as a secret in the <code>carduus</code> scope.</p> <pre><code>(cat &lt;&lt; EOF\n-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\nEOF\n) | databricks secrets put-secret carduus PrivateKey\n</code></pre> <p>Add the secrets for the public keys of the third party organizations you will be sending and receiving tokenized data to/from.</p> <pre><code>(cat &lt;&lt; EOF\n-----BEGIN PUBLIC KEY-----\n...\n-----END PUBLIC KEY-----\nEOF\n) | databricks secrets put-secret carduus AcmeCorpPublicKey\n</code></pre>"},{"location":"guides/databricks/#cluster-setup","title":"Cluster Setup\u00b6","text":"<p>Add spark configuration properties to your custer by reading from the secrets created above. Your organization's private key must be stored under the <code>carduus.token.privateKey</code> key and all third party public keys must be stored under a key with the format <code>carduus.token.publicKey.&lt;recipient&gt;</code> where <code>&lt;recipient&gt;</code> is the name you would like to associate with the public key of a specific recipient that you will send data to.</p> <pre><code>carduus.token.privateKey {{secrets/carduus/PrivateKey}}\ncarduus.token.publicKey.AcmeCorp {{secrets/carduus/AcmeCorpPublicKey}}\n</code></pre>"},{"location":"guides/databricks/#notebook-setup","title":"Notebook setup\u00b6","text":"<p>Ensure the <code>carduus</code> package is installed in your notebook's python environment. The package can also be installed across the entire cluster.</p>"},{"location":"guides/databricks/#tokenization","title":"Tokenization\u00b6","text":"<p>For more information on tokenization see the Carduus getting started guide.</p>"},{"location":"guides/databricks/#sender-transcryption","title":"Sender Transcryption\u00b6","text":"<p>For more information on transcryption see the Carduus getting started guide.</p>"},{"location":"guides/databricks/#recipient-transcryption","title":"Recipient Transcryption\u00b6","text":"<p>You can also load secrets via <code>dbutils</code> and provide a custom key provider to Carduus.</p>"},{"location":"guides/getting-started/","title":"Getting Started","text":"<p>This guide provides a quick tour of the main features of Carduus, including instructions for how most users will be interacting with the library.</p> <p> Carduus has not reached a v1.0 release yet and therefore the API and behaviors are subject to change. Use at your own risk! See the contributing guide if you would like to help the project.</p>"},{"location":"guides/getting-started/#installation","title":"Installation","text":"<p>Carduus is a cross-platform python library built on top of PySpark. It supports the following range of versions:</p> <ul> <li>Python: 3.9+</li> <li>PySpark: 3.5+</li> </ul> <p>The latest stable release of carduus can be installed from PyPI into your active Python environment using <code>pip</code>.</p> <pre><code>pip install carduus\n</code></pre> <p>You can also build Carduus from source using Poetry. The source code is hosted on Github. Checkout the commit you wish to build and run  <code>poetry build</code> in the project's root.</p>"},{"location":"guides/getting-started/#encryption-keys","title":"Encryption Keys","text":"<p>Carduus's tokenization capabilities require the use of private and public encryption keys. Carduus users are expected to manage their own encryption keys.</p> <p>There are 3 kinds of encryption keys that play different roles:</p> <ol> <li>Your private RSA key - Used to transcrypt incoming data and derive a symmetric encryption key used to tokenize PII. This key must never be shared or accessed by untrusted parties.</li> <li>Your public RSA key - The public key counterpart to your private key. Will be shared with trusted parties that will be sending you tokenized data.</li> <li>Trusted partner public keys - A collection of public keys from the various trusted parties that you will be sending tokenized to.</li> </ol>"},{"location":"guides/getting-started/#generating-new-keys","title":"Generating New Keys","text":"<p>Carduus expects encryption keys to be represented the PEM encoding. Private keys should use the PKCS #8 format and public keys should be formatted as SubjectPublicKeyInfo. Carduus recommends a key size of 2048 bits.</p> <p>You can generate these keys using tools like <code>openssl</code> or by calling the <code>generate_pem_keys</code> function provided by Carduus. This function will return a <code>tuple</code> containing 2 instances of <code>bytes</code>. The first is the PEM data for your private key that you must keep secret. The second is the PEM data for your public key that can may share with the parties you intend to receive data from.</p> <p>You can decode these keys into strings of text (using UTF-8) or write them into a <code>.pem</code> file for later use. </p> <pre><code>from carduus.keys import generate_pem_keys\n\nprivate, public = generate_pem_keys()  # Or provide key_size= \n\nprint(private.decode())\n# -----BEGIN PRIVATE KEY-----\n# ... [ Base64-encoded private key ] ...\n# -----END PRIVATE KEY-----\n\nprint(public.decode())\n# -----BEGIN PUBLIC KEY-----\n# ... [ Base64-encoded public key ] ...\n# -----END PUBLIC KEY-----\n</code></pre>"},{"location":"guides/getting-started/#providing-keys-to-carduus","title":"Providing Keys to Carduus","text":"<p>Carduus has multiple ways of for users to provide their encryption keys.</p> <p>The default option is to load encryption keys as Spark session configuration properties. This behavior is designed to integrate with secret management services that inject secrets into the Spark session properties, such as the Databricks secret manager. For more information on using Carduus on Databricks, see the Databricks usage guide.</p> <p>Your private key is stored under the <code>carduus.token.privateKey</code> property. The public keys of each party you send data to is stored under a property with the prefix <code>carduus.token.publicKey.</code> followed by the name you would like to associate with the party. For example, the public key for Acme Corp would be stored under the <code>carduus.token.publicKey.AcmeCorp</code> property.</p> <p>These properties can be set when starting the spark cluster, or at runtime using the <code>SparkSession</code> method <code>.conf.set()</code> as shown below.</p> <p> The following snippet is only a demonstration. You should never hard-code your private encryption keys. Instead you should call out to a dedicated secret management service that ensure only authorized users are accessing the key.</p> <pre><code># Get a reference to the active spark session or create one with SparkSession.builder.getOrCreate()\nspark: SparkSession = ... \n\nspark.conf.set(\n  \"carduus.token.privateKey,\n  \"\"\"-----BEGIN PRIVATE KEY-----\n... [ Base64-encoded private key ] ...\n-----END PRIVATE KEY-----\n\"\"\"\n)\n\nspark.conf.set(\n  \"carduus.token.publicKey.AcmeCorp\",\n  \"\"\"-----BEGIN PUBLIC KEY-----\n... [ Base64-encoded public key ] ...\n-----END PUBLIC KEY-----\n\"\"\",\n)\n</code></pre> <p>Carduus also provides an <code>SimpleKeyProvider</code> class that simply holds an in-memory collection of keys as instances of <code>bytes</code>.This allows users to manage all encryption keys using whatever method they way and </p> <p>Some users may way a more tightly coupled integration between Carduus and their preferred system for managing secrets and encryption keys. For example, you may wish for Carduus to delegate to your authentication or access control services before giving Carduus, and the user, access to certain keys. To solve this problem, Carduus accepts any implementation of the <code>EncryptionKeyProvider</code> interface. See the custom key provider guide for more details.</p>"},{"location":"guides/getting-started/#tokenization","title":"Tokenization","text":"<p>Tokenization refers to the process of replacing PII with encrypted tokens using a one-way cryptographic function. Carduus implements the OPPRL tokenization protocol, which performs a standard set of PII normalizations and enhancements such that records pertaining to the same subject are more likely to receive the same token despite minor differences in PII representation across records. The OPPRL protocol hashes the normalized PII and then encrypts the hashes with a symmetric encryption based on a secret key derived from your private RSA key. In the event that the private encryption key of one party is compromised, there risk to all other parties is mitigated by the fact that everyone's tokens are encrypted with a different key.</p> <p>To demonstrate the tokenization process, we will use a dataset of 5 records shown below. Each record is assigned a <code>label</code> that corresponds to the true identity of the subject.</p> <pre><code>pii = spark.createDataFrame(\n    [\n        (1, \"Jonas\", \"Salk\", \"male\", \"1914-10-28\"),\n        (1, \"jonas\", \"salk\", \"M\", \"1914-10-28\"),\n        (2, \"Elizabeth\", \"Blackwell\", \"F\", \"1821-02-03\"),\n        (3, \"Edward\", \"Jenner\", \"m\", \"1749-05-17\"),\n        (4, \"Alexander\", \"Fleming\", \"M\", \"1881-08-06\"),\n    ],\n    (\"label\", \"first_name\", \"last_name\", \"gender\", \"birth_date\")\n)\npii.show()\n# +-----+----------+---------+------+----------+\n# |label|first_name|last_name|gender|birth_date|\n# +-----+----------+---------+------+----------+\n# |    1|     Jonas|     Salk|  male|1914-10-28|\n# |    1|     jonas|     salk|     M|1914-10-28|\n# |    2| Elizabeth|Blackwell|     F|1821-02-03|\n# |    3|    Edward|   Jenner|     m|1749-05-17|\n# |    4| Alexander|  Fleming|     M|1881-08-06|\n# +-----+----------+---------+------+----------+\n</code></pre> <p>To perform tokenization, call the <code>tokenize</code> function and pass it the PII <code>DataFrame</code>, a column mapping, and a collection of specifications for token you want to generate. You may optionally pass an instance of <code>EncryptionKeyProvider</code>, but all code snippets shown in this guide assume the default key service is used (unless otherwise specified) and therefore encryption keys will be read from the spark session properties.</p> <pre><code>from carduus.token import tokenize, OpprlPii, OpprlToken\ntokens = tokenize(\n    pii,\n    pii_transforms=dict(\n        first_name=OpprlPii.first_name,\n        last_name=OpprlPii.last_name,\n        gender=OpprlPii.gender,\n        birth_date=OpprlPii.birth_date,\n    ),\n    tokens=[OpprlToken.token1, OpprlToken.token2],\n)\n# +-----+--------------------+--------------------+\n# |label|       opprl_token_1|       opprl_token_2|\n# +-----+--------------------+--------------------+\n# |    1|d2tUj3yRFPIBSwR/n...|DQhKG+AMgrFh16dLi...|\n# |    1|d2tUj3yRFPIBSwR/n...|DQhKG+AMgrFh16dLi...|\n# |    2|2wnRWhN9Y4DBMeuvw...|A7fUKAZi/Ra2T6p8y...|\n# |    3|I17X+CT3kjqB9l0rA...|qGCUVyI7MJLkQ9SSr...|\n# |    4|6Ee3NabHaa/lyKsrp...|dbwNqy0rN6hFoHJYn...|\n# +-----+--------------------+--------------------+\n</code></pre> <p>Notice that both records with <code>label = 1</code> received the same pair of tokens despite slight representation differences in the original PII.</p> <p>The <code>pii_transforms</code> argument is a dictionary that maps column names from the <code>pii</code> DataFrame to the corresponding OPPRL PII field. This tells Carduus how to normalize and enhance the values found in that column. For example, the <code>OpprlPii.first_name</code> object will apply name cleaning rules to the values found in the <code>first_name</code> column and automatically derive additional PII columns called <code>first_initial</code> and <code>first_soundex</code> which are used to create both OPPRL tokens.</p> <p>The <code>tokens</code> argument is collection of OPPRL token specifications that tell Carduus which PII fields to jointly hash and encrypt to create each token. The current OPPRL protocol supports two token specifications, described below:</p> Token Fields to jointly encrypt <code>OpprlToken.token1</code> <code>first_initial</code>, <code>last_name</code>, <code>gender</code>, <code>birth_date</code> <code>OpprlToken.token2</code> <code>first_soundex</code>, <code>last_soundex</code>, <code>gender</code>, <code>birth_date</code> <p> Why two tokens? </p> <p>Each use case has a different tolerance for false positive and false negative matches. By producing multiple tokens for each record using PII attributes, each user can customize their match logic to trade-off between different kinds of match errors. Linking records that match on either token will result in fewer false negatives, and linking records that match both tokens will result in fewer false positives.</p>"},{"location":"guides/getting-started/#transcryption","title":"Transcryption","text":"<p> noun: trans- (latin: across) -crypt (greek: hidden, secret)</p> <p>The process of transforming a ciphertext produced by one encryption into a ciphertext of a different encryption without emitting the original plaintext.</p> <p>Transcryption is performed when a user wants to share tokenized data with another party. The sender and recipient each have a corresponding transcryption function that must be invoked to ensure safe transfer of data between trusted parties. The sender performs transcryption to replace their tokens with \"ephemeral tokens\" that are specific to the transaction. In other words, the ephemeral tokens do not match the sender's tokens, the recipients data, or the ephemeral tokens from prior transactions between any sender and recipient. </p> <p>Furthermore, records from the same dataset that have identical PII will be assigned unique ephemeral tokens. This destroys the utility of the tokens until the recipient performs the reverse transcryption process using their private key. This is beneficial in the event that a third party gains access to the dataset during transfer (eg. an if transcrypted datasets are delivered over an insecure connection) because records pertaining to the same subject cannot be associated with each other.</p>"},{"location":"guides/getting-started/#sender","title":"Sender","text":"<p>Carduus provides the <code>transcrypt_out</code> function in for the sender to call on their tokenized datasets. In the following code snippet, notice the 2 records pertaining to the same subject (<code>label = 1</code>) no longer have identical tokens. The <code>tokens_to_send</code> DataFrame can safely be written files or a database and delivered to the recipient.</p> <pre><code>tokens_to_send = transcrypt_out(\n    tokens, \n    token_columns=(\"opprl_token_1\", \"opprl_token_2\"), \n    recipient=\"AcmeCorp\",\n)\ntokens.to_send.show()\n# +-----+--------------------+--------------------+\n# |label|       opprl_token_1|       opprl_token_2|\n# +-----+--------------------+--------------------+\n# |    1|IL17HgISJv5ol+ftJ...|YPnfuGBBhbOZChlhR...|\n# |    1|IVwfYY0dbmFc6cf0/...|jF8N2HYEYPr5lFSSx...|\n# |    2|I5Oe3oC0heF8L+Zcy...|BkBPzMDXeKlprUd8l...|\n# |    3|dOQtYZZV8j/E6wGMB...|FU6MbMjsU8WrJoiXa...|\n# |    4|N0VzhvFHrTtWNt+P7...|jvbFTWbmBzB06lDpv...|\n# +-----+--------------------+--------------------+\n</code></pre> <p>The <code>token_columns</code> argument is a iterable collection containing the column names of the <code>tokens</code> DataFrame that correspond to tokens that need to be transcrypted.</p> <p>The <code>recipient</code> argument denotes the name given to the public key associated with the intended recipient. If using the default encryption key provider (via Spark session properties) the above code snippet will grab the public key from <code>carduus.token.publicKey.AcmeCorp</code> spark session property.</p>"},{"location":"guides/getting-started/#recipient","title":"Recipient","text":"<p>The <code>transcrypt_in</code> function provides the transcryption process for the recipient. It is called on a dataset produced by the sender using <code>transcrypt_out</code> to convert ephemeral tokens into normal tokens that will match other tokenized datasets maintained by the recipient, including prior datasets delivered from the same sender.</p> <p>For this demonstration, we will load the private encryption key of our hypothetical recipient, Acme Corp, in order to process the ephemeral tokens we created in the previous section as if we were operating in the recipient's environment. This is done using an <code>SimpleKeyProvider</code> that is passed to the transcryption function to override where Carduus pull keys from.</p> <p>Notice that the first 2 records pertaining to the same subject (label = 1) have identical tokens again, but do these tokens are not the same as the original tokens because they are encrypted with the scheme for the recipient.</p> <pre><code>from carduus.keys import SimpleKeyProvider\nfrom carduus.token import transcrypt_in\n\nacme_keys = SimpleKeyProvider(\n  # Another reminder to never hardcode your private encryption keys in real use cases!\n  private_key=b\"\"\"-----BEGIN PRIVATE KEY-----\n... [ Base64-encoded private key ] ...\n-----END PRIVATE KEY-----\n\"\"\",\n  public_keys={},\n)\n\nacme_tokens = transcrypt_in(\n    tokens_to_send, \n    token_columns=(\"opprl_token_1\", \"opprl_token_2\"),\n    key_service=acme_keys,\n)\nacme_tokens.show()\n# +-----+--------------------+--------------------+\n# |label|       opprl_token_1|       opprl_token_2|\n# +-----+--------------------+--------------------+\n# |    1|O47siK/9rItAv6lwa...|uoPojmvjl3Mk734Ul...|\n# |    1|O47siK/9rItAv6lwa...|uoPojmvjl3Mk734Ul...|\n# |    2|LfRQxBPEW0tEskwxt...|P9PLhpSz+kWSSVmYQ...|\n# |    3|QWvpT0wMEezlurVFM...|W9BxmxZf1/yqIDx3W...|\n# |    4|aS/BfI5qw8UnhOWUX...|nWfWyxQcrSfeiMEHr...|\n# +-----+--------------------+--------------------+\n</code></pre> <p>As with <code>transcrypt_out</code>, the <code>token_columns</code> argument is a iterable collection containing the column names of the <code>tokens</code> DataFrame that correspond to tokens that need to be transcrypted. </p> <p>The <code>key_service</code> argument overrides the default key provider with our Acme Corp keys. The <code>tokenize</code> and <code>transcrypt_out</code> functions also have this parameter.</p>"},{"location":"guides/getting-started/#deployment","title":"Deployment","text":"<p>Carduus is a Python library that uses PySpark to parallelize and distribute the tokenization and transcryption workloads. Your application that uses Carduus can be submitted to any compatible Spark cluster, or use a connection to a remote spark cluster. Otherwise, Carduus will start a local Spark process that uses the resources of the host machine.</p> <p>For more information about different modes of deployment, see the official Spark documentation.</p> <ul> <li>Submitting Applications to a Spark cluster</li> <li>Spark Connect</li> <li>Spark Standalone Mode</li> </ul>"},{"location":"guides/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Reference the full API</li> <li>Learn more about using Carduus and extending it's functionality from the advanced user guides:<ul> <li>Implementing a custom encryption key provider</li> <li>Using Carduus on Databricks</li> <li>Defining custom token specifications</li> <li>Adding support for custom PII attributes</li> </ul> </li> </ul>"},{"location":"opprl/PROTOCOL/","title":"OPPRL Protocol","text":"<p> Warning!   This specification is incomplete. Many sections are missing and the existing details may change. If you are interested in contributing to the specification, see the Contributing Guide</p>"},{"location":"opprl/PROTOCOL/#overview","title":"Overview","text":"<p>This document is a specification for the Open Privacy Preserving Record Linkage (OPPRL) protocol, which brings ______. This capability is often refered to as \"tokenization\".  The protocol is designed with the following goals:</p> <ul> <li>Interoperability - Implementations can be created in many data systems while </li> <li>Security - Carefully selected encryption algorithms are used at each point in the process to mitigate any chance of catastrophic failure or information leakage.</li> <li>Decentralization - No trusted third parties are needed to act as centralized authories. No single point of failure.</li> <li>Scalability - Tokenization is an embarrassingly parallel task that should scale efficently to billions of records.</li> </ul> <p>Privacy Preserving Record Linkage (PPRL) is crucial component to data de-identification systems. PPRL obfuscate identifying attributes or other sensitive information about the subjects described in the records of a dataset while still preserving the ability to link records pertaining to the same subject through the use of an encrypted token. This practice is sometimes referred to as \"tokenization\" and is one of the components of data deidenfication.</p> <p>The task of PPRL is to replace the attributes of a every record denoting Personally Identifiable Information (PII) with a token produced by a one-way cryptographic function. This prevents observers of the tokenized data from obtaining the PII. The tokens are produced deterministically such that input records with the same, or similar, PII attributes will produce an identical token. This allows practitioners to associate records across datasets that are highly likely to belong to the same data subject without having acces to PII.</p> <p>Tokenization is also used when data is shared between organizations to limit, or in some cases fully mitigate, the risk of subject re-identification in the event that an untrusted third party gains access to a dataset containing sensitive data. Each party produced encrypted tokens using a different secret key so that any compromised data asset is, at worst, only matchable to other datasets mantained by the same party. During data sharing transactions, a specific \"transcryption\" data flow is used to first re-encrypt the sender's tokens into ephemeral tokens that do not match tokens in any other dataset and can only be ingested using the receipiants secret key. At no point in the \"transcryption\" data flow is the orginoal PII used.</p>"},{"location":"opprl/PROTOCOL/#glossary","title":"Glossary","text":"Term Definition Data Asset A collection of records with attributes. Can be a single dataset, or a collection of related datasets. Subject A person who is being decribed by one or more recoreds in a data asset. PPRL attempts to obfuscate the identity of the subject. Attribute A single field of a record denoting one piece of information about the subject. PII Personally Identifying Information. Attributes of a data asset that can be used to determine the identity of a subject. Examples include name, residential address, gender, age, phone number, email, as well as other demographic or socio-ecominic attributes. Token An string of text derived deterministically by a one-way cryptographic function. Implementer An individual or organization that creates a software tool that implements this specification. User The end user of an OPPRL implementation. Custodian An individual or organization in possession of a data asset. Receipient An individual or organization that receives a data asset from a custodian."},{"location":"opprl/PROTOCOL/#encryption-keys","title":"Encryption Keys","text":"<p>Every user of an OPPRL implementation must have asymmetric encryption key pair consisting of a public key and corresponding private key. The public key is not secret and can be shared with parties that the user intends to share data with. A custodian will use the public key of a specific receiptiant to encrypt ephemeral tokens that can only be decrypted by the receiptiant using their private key.</p> <p>Implementers may choose any asymettric encryption algorithm that is sufficiently safe, however users must </p> <p>The private key is also used to derive a third encryption key via a hash function. This key is a random </p>"},{"location":"opprl/PROTOCOL/#tokenization","title":"Tokenization","text":""},{"location":"opprl/PROTOCOL/#normalization","title":"Normalization","text":""},{"location":"opprl/PROTOCOL/#enhancement","title":"Enhancement","text":""},{"location":"opprl/PROTOCOL/#tokens","title":"Tokens","text":"Token Fields 1 First initial, Last name, Gender, Birth date 2 First soundex, Last soundex, Gender, Birth date"},{"location":"opprl/PROTOCOL/#transcryption","title":"Transcryption","text":""},{"location":"opprl/PROTOCOL/#sender","title":"Sender","text":""},{"location":"opprl/PROTOCOL/#receipiant","title":"Receipiant","text":""},{"location":"opprl/contrib/","title":"Contributing to the OPPRL Protocol","text":"<p> This specification is incomplete.</p>"},{"location":"opprl/contrib/#contributing-opprl-evaluation-data","title":"Contributing OPPRL Evaluation Data","text":"<p>Post on the discussion board in the OPPRL section. </p>"},{"location":"opprl/contrib/#contributing-research","title":"Contributing Research","text":"<p>Post on the discussion board in the OPPRL section. </p>"},{"location":"opprl/contrib/#proposing-changes","title":"Proposing Changes","text":"<p>Open a PR to spec document in the Carduus repository.</p>"},{"location":"opprl/spec/","title":"OPPRL v0.1 Specification","text":"<p> Warning</p> <p>This specification is incomplete and actively being written collaboratively in the open. Many sections are missing and the specifics may change dramatically.</p> <p>If you would like to join </p> <p>Authors of OPPRL implementations should expect breaking changes, and interoperability between implementation cannot be guarenteed until an official version 1.0 is published.</p> <p>Privacy Preserving Record Linkage (PPRL) is crucial component to data de-identification systems. PPRL obfuscate identifying attributes or other sensitive information about the subjects described in the records of a dataset while still preserving the ability to link records pertaining to the same subject through the use of an encrypted token. This practice is sometimes referred to as \"tokenization\" and is one of the components of data deidenfication.</p> <p>The task of PPRL is to replace the attributes of a every record denoting Personally Identifiable Information (PII) with a token produced by a one-way cryptographic function. This prevents observers of the tokenized data from obtaining the PII. The tokens are produced deterministically such that input records with the same, or similar, PII attributes will produce an identical token. This allows practitioners to associate records across datasets that are highly likely to belong to the same data subject without having acces to PII.</p> <p>Tokenization is also used when data is shared between organizations to limit, or in some cases fully mitigate, the risk of subject re-identification in the event that an untrusted third party gains access to a dataset containing sensitive data. Each party produced encrypted tokens using a different secret key so that any compromised data asset is, at worst, only matchable to other datasets mantained by the same party. During data sharing transactions, a specific \"transcryption\" data flow is used to first re-encrypt the sender's tokens into ephemeral tokens that do not match tokens in any other dataset and can only be ingested using the receipiants secret key. At no point in the \"transcryption\" data flow is the orginoal PII used.</p>"},{"location":"opprl/spec/#about-this-specification","title":"About this specification","text":"<ul> <li>SemVer</li> </ul>"},{"location":"opprl/spec/#glossary","title":"Glossary","text":"<ul> <li>Data Asset: A collection of records with attributes. Can be a single dataset, or a collection of related datasets.</li> <li>Subject: A person who is being decribed by one or more recoreds in a data asset.</li> <li>PII: Personally Identifying Information. Attributes of a data asset that can be used to determine the identity of a subject. Examples include name, residential address, gender, age, phone number, email, as well as other demographic, socio-ecominic, and </li> <li>Token: An arbitrary string of text derived deterministically from PII that can be used to identify records pertaining the same subject. Tokens provide nearly no information about the underlying PII they are generated from and thus can be used to replace PII in a data asset</li> </ul>"},{"location":"opprl/spec/#1-tokenization","title":"1 Tokenization","text":"<p>Convertion of PII attributes into tokens.</p>"},{"location":"opprl/spec/#requirements","title":"Requirements","text":""},{"location":"opprl/spec/#11-data-flow","title":"1.1 Data Flow","text":"<p>Inputs:</p> <ol> <li>An AES encryption key unique to data asset.</li> <li>PII Transformations</li> <li>Token specificaitnos.</li> </ol>"},{"location":"opprl/spec/#111-normalization","title":"1.1.1 Normalization","text":""},{"location":"opprl/spec/#112-enhancement","title":"1.1.2 Enhancement","text":""},{"location":"opprl/spec/#113-fragmentation","title":"1.1.3 Fragmentation","text":""},{"location":"opprl/spec/#114-hashing","title":"1.1.4 Hashing","text":""},{"location":"opprl/spec/#115-encryption","title":"1.1.5 Encryption","text":""},{"location":"opprl/spec/#116-base64-encoding","title":"1.1.6 Base64 Encoding","text":""},{"location":"opprl/spec/#2-transcyption","title":"2 Transcyption","text":"<p>The re-encryption of tokens for the purpose of safely delivering tokenized data between parties.</p> <p>Ephemeral tokens.</p>"},{"location":"opprl/spec/#requirements_1","title":"Requirements","text":""},{"location":"opprl/spec/#21-sender-data-frow","title":"2.1 Sender Data Frow","text":"<p>Inputs:</p> <ol> <li>The AES encryption key used to encrypt the PII hashes.</li> <li>The public RSA key of the receiver.</li> </ol> <p>The entire data flow must be performed by the sender with no malicious observers intercepting intermediate values.</p>"},{"location":"opprl/spec/#211-decode-base64","title":"2.1.1 Decode Base64","text":""},{"location":"opprl/spec/#212-aes-decryption","title":"2.1.2 AES Decryption","text":""},{"location":"opprl/spec/#213-rsa-encryption","title":"2.1.3 RSA Encryption","text":""},{"location":"opprl/spec/#214-encode-base64","title":"2.1.4 Encode Base64","text":""},{"location":"opprl/spec/#22-receiver-data-flow","title":"2.2 Receiver Data Flow","text":"<p>Inputs:</p> <ol> <li>The private RSA key of the receiver. It must corresponds to the public key used by the sender.</li> <li>An AES encryption key unique to the receiver.</li> </ol>"},{"location":"opprl/spec/#221-decode-base64","title":"2.2.1 Decode Base64","text":""},{"location":"opprl/spec/#222-rsa-decryption","title":"2.2.2 RSA Decryption","text":""},{"location":"opprl/spec/#223-aes-encryption","title":"2.2.3 AES Encryption","text":""},{"location":"opprl/spec/#224-encode-base64","title":"2.2.4 Encode Base64","text":""},{"location":"opprl/spec/#3-opprl-pii-transformations","title":"3 OPPRL PII Transformations","text":""},{"location":"opprl/spec/#31-normalizations","title":"3.1 Normalizations","text":""},{"location":"opprl/spec/#person-names","title":"Person Names","text":""},{"location":"opprl/spec/#gender","title":"Gender","text":""},{"location":"opprl/spec/#dates","title":"Dates","text":""},{"location":"opprl/spec/#32-enhancements","title":"3.2 Enhancements","text":""},{"location":"opprl/spec/#person-names_1","title":"Person Names","text":""},{"location":"opprl/spec/#dates_1","title":"Dates","text":""},{"location":"opprl/spec/#5-opprl-token-specifications","title":"5 OPPRL Token Specifications","text":""}]}